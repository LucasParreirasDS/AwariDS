{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LucasParreirasDS/AwariDS/blob/main/Deep%20Learning/%5BAWARI_DS_14_02%5D_Pr%C3%A1tica_NLP_com_Spacy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![header-notebooks.png](data:image/png;base64,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)\n",
        "\n",
        "Prática da **Aula 14: Machine Learning IV**, do curso de **Data Science** da **[Awari](https://awari.com.br/)**. Para utilizá-la, vá no menu \"Arquivo\" e, em seguida, na opção \"Salvar uma cópia no Drive\". Isto criará uma cópia deste notebook em uma pasta chamada \"Colab Notebooks\", no seu Google Drive pessoal. Use a cópia para criar novas células de código ou executar as células desta prática.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "DpfClUSPN2XJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-n_QTAHFdte"
      },
      "source": [
        "# **NLP com Spacy**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Introdução**\n",
        "\n",
        "Esta prática é uma introdução ao trabalho com **linguagem natural** (às vezes chamada de \"análise de texto\") em Python, usando a biblioteca [**spaCy**](https://spacy.io/usage/spacy-101).\n",
        "\n",
        "Em uma empresa, por exemplo, normalmente existem contratos (contratos de venda, acordos de trabalho, parcerias), existem faturas, existem apólices de seguro, existem regulamentos e assim por diante. Todos eles são representados como texto. Tudo isso é processável por meio de NLP.\n",
        "\n",
        "Você pode encontrar alguns acrônimos que explicam este domínio: **processamento de linguagem natural (NLP)**, **compreensão de linguagem natural (NLU)** e **geração de linguagem natural (NLG)** (\"ler texto\", \"entender significado\", \"escrever texto\", respectivamente). Cada vez mais essas tarefas se sobrepõem e se combinam.\n",
        "\n",
        "A biblioteca spaCy fornece recursos para uma ampla variedade de tarefas em linguagem natural. Tanto que se tornou uma das mais usadas nesse domínio.\n",
        "\n",
        "Nesta prátiva, vamos usar NLP e spaCy para entender como esta área de Deep Learning funciona."
      ],
      "metadata": {
        "id": "pSZSbUCYRm_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Instalando spaCy**\n",
        "\n",
        "Primeiro, precisamos instalar spaCy. Podemos usar `pip` ou `conda` para isso\n",
        "\n",
        "Na [documentação](https://spacy.io/usage) da biblioteca, há instruções detalhadas de como fazer isso para cada sistema operacional.\n",
        "\n",
        "Em geral, a execução dos seguintes comandos deve bastar para Linux, macOS e Windows:\n",
        "\n",
        "```\n",
        "# Instalando spaCy\n",
        "pip install -U pip setuptools wheel\n",
        "pip install -U spacy\n",
        "python -m spacy download en_core_web_sm\n",
        "```\n",
        "\n",
        "Após a instalação, podemos importar a biblioteca e começar a trabalhar."
      ],
      "metadata": {
        "id": "tTsEwJ9rNgMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalando spaCy\n",
        "!pip install -U pip setuptools wheel\n",
        "!pip install -U spacy\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "LOhcD93bqxSA",
        "outputId": "bbb7c1d5-a69c-4635-c75d-3d26dbb8dcb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-23.2.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (67.7.2)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-68.2.2-py3-none-any.whl (807 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.9/807.9 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.41.2)\n",
            "Installing collected packages: setuptools, pip\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.7.2\n",
            "    Uninstalling setuptools-67.7.2:\n",
            "      Successfully uninstalled setuptools-67.7.2\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pip-23.2.1 setuptools-68.2.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "pkg_resources",
                  "setuptools"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (68.2.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m2023-09-21 17:54:13.962430: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-09-21 17:54:15.706294: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (68.2.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.3)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AAsyAvAUFdti"
      },
      "outputs": [],
      "source": [
        "# Importando spaCy\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **spaCy em português**\n",
        "\n",
        "O exemplo acima usa spaCy em inglês, que é o padrão. Mas também podemos usá-lo para a língua portuguesa, da seguinte forma:"
      ],
      "metadata": {
        "id": "-g5JsozKNty8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Baixando idioma português\n",
        "!python -m spacy download pt"
      ],
      "metadata": {
        "id": "ujC-I939OmMg",
        "outputId": "6ee9c7ee-1031-447a-93b9-c04558a15c63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-09-21 17:55:08.113334: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'pt' are deprecated. Please use the\n",
            "full pipeline package name 'pt_core_news_sm' instead.\u001b[0m\n",
            "Collecting pt-core-news-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.6.0/pt_core_news_sm-3.6.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from pt-core-news-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (68.2.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (0.1.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.1.3)\n",
            "Installing collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-3.6.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Baixando o modelo\n",
        "!spacy download pt_core_news_sm"
      ],
      "metadata": {
        "id": "QZYnC02BGR91",
        "outputId": "a1e28eae-76a4-48a8-8674-4c1f2518f56e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-09-21 17:55:22.420347: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting pt-core-news-sm==3.6.0\n",
            "  Using cached https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.6.0/pt_core_news_sm-3.6.0-py3-none-any.whl (13.0 MB)\n",
            "Requirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from pt-core-news-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (68.2.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (0.1.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.1.3)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('pt_core_news_sm')\n",
        "# Para voltar ao inglês, executar: nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "EIbCxKCnGVJM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Processando texto**\n",
        "\n",
        "Vamos analisar uma frase simples pelo analisador de linguagem natural, para ver como funciona:"
      ],
      "metadata": {
        "id": "LipjdxEJO4jp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NzErmxeAFdtk",
        "outputId": "d0eb5527-2671-4ff3-fe20-eb0b5c497bc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A o DET True\n",
            "chuva chuva NOUN False\n",
            "no em o ADP True\n",
            "Brasil Brasil PROPN False\n",
            "ocorre ocorrer VERB False\n",
            "mais mais ADV True\n",
            "onde onde ADV True\n",
            "tem ter VERB True\n",
            "florestas floresta NOUN False\n",
            ". . PUNCT False\n"
          ]
        }
      ],
      "source": [
        "text = \"A chuva no Brasil ocorre mais onde tem florestas.\"\n",
        "doc = nlp(text)\n",
        "\n",
        "for token in doc:\n",
        "    print(token.text, token.lemma_, token.pos_, token.is_stop)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primeiro criamos um [doc](https://spacy.io/api/doc) a partir do texto, que é um container para um documento e todas as suas anotações.\n",
        "\n",
        "Em seguida, percorremos o documento para ver o que o spaCy analisou.\n",
        "\n",
        "O resultado saiu um pouco confuso. Vamos tratar o resultado por meio de um DataFrame do [Pandas](https://pandas.pydata.org/):"
      ],
      "metadata": {
        "id": "XyqEsjAqQI3P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9qL9PX0Fdtl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "cols = (\"text\", \"lemma\", \"POS\", \"explain\", \"stopword\")\n",
        "rows = []\n",
        "\n",
        "for t in doc:\n",
        "    row = [t.text, t.lemma_, t.pos_, spacy.explain(t.pos_), t.is_stop]\n",
        "    rows.append(row)\n",
        "\n",
        "df = pd.DataFrame(rows, columns=cols)\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neste caso simples, todo o documento é apenas uma frase curta. Para cada palavra nessa frase, o spaCy criou um [token](https://spacy.io/api/token) e acessamos os campos em cada token para mostrar:\n",
        "\n",
        "- texto puro (*raw text*);\n",
        "- [lemma](https://en.wikipedia.org/wiki/Lemma_(morphology)), isto é, a raiz da palavra;\n",
        "- parte do discurso [*part of speech*](https://en.wikipedia.org/wiki/Part_of_speech);\n",
        "- um sinalizador (\"flag\") para saber se a palavra é uma \"stopword\" (palavra irrelevante), ou seja, uma palavra comum que pode ser filtrada."
      ],
      "metadata": {
        "id": "IW_05yEsQ4dy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para efeito de entendimento, podemos ter disponível:\n",
        "\n",
        "- **lemma:** raiz da palavra;\n",
        "- **pos:** parte da fala;\n",
        "- **tag:** informações morfológicas, como se o verbo está no passado;\n",
        "- **dep:** dependência sintática;\n",
        "- **shape:** formato (maiúsculo, minúsculo, dígitos);\n",
        "- **alpha:** se é alfabético;\n",
        "- **stop:** se é stopword."
      ],
      "metadata": {
        "id": "qie4gQnBR6qK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Em seguida, vamos usar outra biblioteca, [displaCy](https://ines.io/blog/developing-displacy), para visualizar a árvore de análise dessa frase:"
      ],
      "metadata": {
        "id": "pBjfP2PSSP39"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cwnAJwaaFdtn",
        "outputId": "9889d3d1-abbe-4739-ff61-203e8daf47cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"pt\" id=\"f59e811046ab4abfb5e7551a019de9b7-0\" class=\"displacy\" width=\"1625\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">A</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">chuva</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">no</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">Brasil</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">ocorre</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">mais</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">onde</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">tem</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">florestas.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f59e811046ab4abfb5e7551a019de9b7-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f59e811046ab4abfb5e7551a019de9b7-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f59e811046ab4abfb5e7551a019de9b7-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,2.0 750.0,2.0 750.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f59e811046ab4abfb5e7551a019de9b7-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f59e811046ab4abfb5e7551a019de9b7-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f59e811046ab4abfb5e7551a019de9b7-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f59e811046ab4abfb5e7551a019de9b7-0-3\" stroke-width=\"2px\" d=\"M245,264.5 C245,89.5 570.0,89.5 570.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f59e811046ab4abfb5e7551a019de9b7-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M570.0,266.5 L578.0,254.5 562.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f59e811046ab4abfb5e7551a019de9b7-0-4\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f59e811046ab4abfb5e7551a019de9b7-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M915.0,266.5 L923.0,254.5 907.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f59e811046ab4abfb5e7551a019de9b7-0-5\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f59e811046ab4abfb5e7551a019de9b7-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f59e811046ab4abfb5e7551a019de9b7-0-6\" stroke-width=\"2px\" d=\"M770,264.5 C770,89.5 1270.0,89.5 1270.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f59e811046ab4abfb5e7551a019de9b7-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1270.0,266.5 L1278.0,254.5 1262.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f59e811046ab4abfb5e7551a019de9b7-0-7\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,177.0 1440.0,177.0 1440.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f59e811046ab4abfb5e7551a019de9b7-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1440.0,266.5 L1448.0,254.5 1432.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from spacy import displacy\n",
        "\n",
        "displacy.render(doc, style=\"dep\", jupyter=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Texto com mais de uma frase**\n",
        "\n",
        "Tudo bem, este é um exemplo simples. Mas como lidar com várias frases?\n",
        "\n",
        "Há recursos para detecção de limite de sentença (*sentence boundary detection (SBD)*), também conhecido como segmentação de sentença (frase), com base em outro recurso do spaCy chamado [sentencizer](https://spacy.io/api/sentencizer):"
      ],
      "metadata": {
        "id": "CKsHxTf-Sa6c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "j-VKP2WKFdto",
        "outputId": "e978d78a-57e0-4f57-d696-6735acdc450c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Estávamos todos no zoológico um dia, eu estava brincando, andando no parapeito da exposição de gorilas.\n",
            "> Eu caí.\n",
            "> Todos gritaram e João pulou atrás de mim, esquecendo que tinha mirtilos no bolso da frente.\n",
            "> Os gorilas simplesmente enlouqueceram.\n"
          ]
        }
      ],
      "source": [
        "text = \"Estávamos todos no zoológico um dia, eu estava brincando, andando no parapeito da exposição de gorilas. Eu caí. Todos gritaram e João pulou atrás de mim, esquecendo que tinha mirtilos no bolso da frente. Os gorilas simplesmente enlouqueceram.\"\n",
        "\n",
        "doc = nlp(text)\n",
        "\n",
        "for sent in doc.sents:\n",
        "    print(\">\", sent)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quando spaCy cria um documento, ele usa um princípio de *tokenização \"não destrutiva\"* significando que os tokens, sentenças etc. são simplesmente índices em um *array* longo.\n",
        "\n",
        "Em outras palavras, eles não dividem o fluxo de texto em pequenos pedaços. Portanto, cada sentença é um [*span*](https://spacy.io/api/span) com um índice *start* e *end* na matriz do documento:"
      ],
      "metadata": {
        "id": "S3KxgnZeTNxy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "StkP7tFRFdtp",
        "outputId": "d194be49-d678-474f-b9a7-8a27938439b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> 0 19\n",
            "> 19 22\n",
            "> 22 40\n",
            "> 40 45\n"
          ]
        }
      ],
      "source": [
        "for sent in doc.sents:\n",
        "    print(\">\", sent.start, sent.end)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos indexar na matriz de documentos para extrair os tokens de uma frase:"
      ],
      "metadata": {
        "id": "OJDzx2ZxT1Gt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "I-0A4RlcFdtq",
        "outputId": "5023df08-b0e0-4d12-c61c-756ade0e7461",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Todos gritaram e João pulou atrás de mim, esquecendo que tinha mirtilos no bolso da frente. Os gorilas simplesmente enlouqueceram."
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "doc[22:45]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ou simplesmente indexe em um token específico, como o verbo \"enlouqueceram\" na última frase:"
      ],
      "metadata": {
        "id": "z4ETQ11fUFRH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "67CJ3j99Fdtq",
        "outputId": "b17389d9-c3ef-4875-fffc-40f5408e8266",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enlouqueceram enlouquecer VERB\n"
          ]
        }
      ],
      "source": [
        "token = doc[43]\n",
        "print(token.text, token.lemma_, token.pos_)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A partir daqui, podemos analisar um documento, segmentar esse documento em sentenças e observar as anotações sobre os tokens em cada sentença."
      ],
      "metadata": {
        "id": "7_LtsucrUhH5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Adquirindo texto**\n",
        "\n",
        "Podemos baixar páginas da web, mas obteremos  HTML e precisamos extrair o texto delas. [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) é um pacote popular para isso.\n",
        "\n",
        "Primeiro, porém, vamos arrumar a casa:"
      ],
      "metadata": {
        "id": "MSS0qIjtWes0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bdi-SSBMFdtr"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "techsM0WFdtr"
      },
      "source": [
        "### **Character encoding**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veja a seguir exemplos de como usar [codecs](https://docs.python.org/3/library/codecs.html) e normalizar unicode [normalize unicode](https://docs.python.org/3/library/unicodedata.html#unicodedata.normalize)."
      ],
      "metadata": {
        "id": "0Gq6KZFmWwXy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RbA9Lj5VFdts",
        "outputId": "7b1367ab-e6b1-4ac1-f6a9-e74da81c4c2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "x = \"Rinôçérôse screams ﬂow not unlike an encyclopædia, \\\n",
        "'TECHNICIÄNS ÖF SPÅCE SHIP EÅRTH THIS IS YÖÜR CÄPTÅIN SPEÄKING YÖÜR ØÅPTÅIN IS DEA̋D' to Spın̈al Tap.\"\n",
        "\n",
        "type(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A variável `x` é uma *string* em Python:"
      ],
      "metadata": {
        "id": "28S46IY9XT0x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Rmo1lEv5Fdts",
        "outputId": "0c9931aa-0d39-418c-d03d-b19c1f685daa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"Rinôçérôse screams ﬂow not unlike an encyclopædia, \\'TECHNICIÄNS ÖF SPÅCE SHIP EÅRTH THIS IS YÖÜR CÄPTÅIN SPEÄKING YÖÜR ØÅPTÅIN IS DEA̋D\\' to Spın̈al Tap.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "repr(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sua tradução para [ASCII](http://www.asciitable.com/) é inutilizável pelos analisadores:"
      ],
      "metadata": {
        "id": "tQD1aNGIXhhU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "B5XDqbbqFdtt",
        "outputId": "59ffdc7a-388a-489b-c10f-e7fce147c783",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"Rin\\\\xf4\\\\xe7\\\\xe9r\\\\xf4se screams \\\\ufb02ow not unlike an encyclop\\\\xe6dia, \\'TECHNICI\\\\xc4NS \\\\xd6F SP\\\\xc5CE SHIP E\\\\xc5RTH THIS IS Y\\\\xd6\\\\xdcR C\\\\xc4PT\\\\xc5IN SPE\\\\xc4KING Y\\\\xd6\\\\xdcR \\\\xd8\\\\xc5PT\\\\xc5IN IS DEA\\\\u030bD\\' to Sp\\\\u0131n\\\\u0308al Tap.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "ascii(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Codificar como [UTF-8](http://unicode.org/faq/utf_bom.html) não ajuda muito:"
      ],
      "metadata": {
        "id": "M3NeFttUXpFK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "PgfmNP4CFdtt",
        "outputId": "4b2e014c-c6a6-4c1e-fc91-74402dfbd743",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b\"Rin\\xc3\\xb4\\xc3\\xa7\\xc3\\xa9r\\xc3\\xb4se screams \\xef\\xac\\x82ow not unlike an encyclop\\xc3\\xa6dia, 'TECHNICI\\xc3\\x84NS \\xc3\\x96F SP\\xc3\\x85CE SHIP E\\xc3\\x85RTH THIS IS Y\\xc3\\x96\\xc3\\x9cR C\\xc3\\x84PT\\xc3\\x85IN SPE\\xc3\\x84KING Y\\xc3\\x96\\xc3\\x9cR \\xc3\\x98\\xc3\\x85PT\\xc3\\x85IN IS DEA\\xcc\\x8bD' to Sp\\xc4\\xb1n\\xcc\\x88al Tap.\""
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "x.encode('utf8')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ignorar caracteres difíceis talvez seja uma estratégia ainda pior:"
      ],
      "metadata": {
        "id": "SAUeFLYAXxHe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ZtjjK4ZRFdtt",
        "outputId": "b0d120ed-42b0-4f6d-c899-2322b0deab99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b\"Rinrse screams ow not unlike an encyclopdia, 'TECHNICINS F SPCE SHIP ERTH THIS IS YR CPTIN SPEKING YR PTIN IS DEAD' to Spnal Tap.\""
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "x.encode('ascii', 'ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPbPf2OyFdtu"
      },
      "source": [
        "No entanto, pode-se *normalizar* o texto e depois codificar…"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_LipNgGjFdtu",
        "outputId": "5f35fe24-aa41-4f89-e800-81d02eaebb2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b\"Rinocerose screams flow not unlike an encyclopdia, 'TECHNICIANS OF SPACE SHIP EARTH THIS IS YOUR CAPTAIN SPEAKING YOUR APTAIN IS DEAD' to Spnal Tap.\""
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import unicodedata\n",
        "\n",
        "unicodedata.normalize('NFKD', x).encode('ascii','ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mesmo antes dessa normalização e codificação, talvez seja necessário converter alguns caracteres explicitamente **antes** da análise (parsing). Por exemplo:"
      ],
      "metadata": {
        "id": "Cl-_ulTnYGM_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "sk-TL8qhFdtu",
        "outputId": "c503a05d-5258-4d9c-b0cc-0e0b4a596309",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"O c\\\\xe9u \\'acima\\' do porto... era da cor da \\'televis\\\\xe3o a cabo\\' - sintonizada no Weather Channel\\\\xae\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "x = \"O céu 'acima' do porto... era da cor da 'televisão a cabo' - sintonizada no Weather Channel®\"\n",
        "\n",
        "ascii(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBHqIdMIFdtu"
      },
      "source": [
        "Considere os resultados para essa linha:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "XVknzIEMFdtv",
        "outputId": "e1849002-7926-44d0-9e9d-943022fc655c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b\"O ceu 'acima' do porto... era da cor da 'televisao a cabo' - sintonizada no Weather Channel\""
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "unicodedata.normalize('NFKD', x).encode('ascii', 'ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqFlOiZxFdtv"
      },
      "source": [
        "...que ainda descarta caracteres que podem ser importantes para analisar uma frase.\n",
        "\n",
        "Portanto, uma abordagem mais avançada poderia ser:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "9gQC4WXdFdtv",
        "outputId": "af98d04a-d628-491e-f00c-4bad8f7cd3f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O ceu 'acima' do porto... era da cor da 'televisao a cabo' - sintonizada no Weather Channel\n"
          ]
        }
      ],
      "source": [
        "x = x.replace('“', '\"').replace('”', '\"')\n",
        "x = x.replace(\"‘\", \"'\").replace(\"’\", \"'\")\n",
        "x = x.replace('…', '...').replace('–', '-')\n",
        "\n",
        "x = unicodedata.normalize('NFKD', x).encode('ascii', 'ignore').decode('utf-8')\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dV6vgCrQFdtv"
      },
      "source": [
        "### **Parsing HTML**\n",
        "\n",
        "Parsing significa analisar. Na função `get_text()`, a seguir, analisaremos o HTML para encontrar todas as tags `<p/>` e, em seguida, extrairemos o texto para elas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "IY6OYihYFdtw"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import traceback\n",
        "\n",
        "def get_text (url):\n",
        "    buf = []\n",
        "\n",
        "    try:\n",
        "        soup = BeautifulSoup(requests.get(url).text, \"html.parser\")\n",
        "\n",
        "        for p in soup.find_all(\"p\"):\n",
        "            buf.append(p.get_text())\n",
        "\n",
        "        return \"\\n\".join(buf)\n",
        "    except:\n",
        "        print(traceback.format_exc())\n",
        "        sys.exit(-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora vamos pegar algum texto de fontes online.\n",
        "Podemos comparar licenças de código aberto hospedadas no site [Open Source Initiative](https://opensource.org/licenses/):"
      ],
      "metadata": {
        "id": "6dGDx-uUZAcx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "MkPXym6dFdtw",
        "outputId": "9a2d3124-bfd5-4047-94f1-1a40c8caab08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Search\n",
            "\n",
            "\n",
            "\t\t\t\t\t\t\t\tSPDX short identifier:\n",
            "\t\t\t\t\t\t\t\tBSD-3-Clause\t\t\t\t\t\t\t\n",
            "\n",
            "Note:\n",
            "> This license has also been called the “New BSD License” or “Modified BSD License\n",
            "> ”.\n",
            "> See also\n",
            "> the 2-clause BSD License.\n",
            "\n",
            "> Copyright <YEAR> <COPYRIGHT HOLDER>\n",
            "\n",
            "> Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n",
            "1.\n",
            "> Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\n",
            "\n",
            "> 2.\n",
            "> Redistributions in binary form must reproduce\n",
            "> the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\n",
            "3.\n",
            "> Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products\n",
            "> derived from this software without specific prior written permission.\n",
            "\n",
            "> THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS\n",
            "> OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n",
            "> A PARTICULAR PURPOSE ARE DISCLAIMED.\n",
            "> IN NO EVENT SHALL\n",
            "> THE COPYRIGHT\n",
            "> HOLDER\n",
            "> OR CONTRIBUTORS BE LIABLE\n",
            "> FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE\n",
            "> GOODS\n",
            "> OR SERVICES\n",
            "> ; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n",
            "> HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
            " \n",
            "\n",
            "> Mastodon\n",
            "Twitter\n",
            "LinkedIn\n",
            " \n",
            "\n",
            "\n",
            "\n",
            "> Proudly powered by WordPress.\n",
            "> Hosted by Pressable.\n"
          ]
        }
      ],
      "source": [
        "lic = {}\n",
        "lic[\"mit\"] = nlp(get_text(\"https://opensource.org/licenses/MIT\"))\n",
        "lic[\"asl\"] = nlp(get_text(\"https://opensource.org/licenses/Apache-2.0\"))\n",
        "lic[\"bsd\"] = nlp(get_text(\"https://opensource.org/licenses/BSD-3-Clause\"))\n",
        "\n",
        "for sent in lic[\"bsd\"].sents:\n",
        "    print(\">\", sent)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Um caso de uso comum para o trabalho em linguagem natural é comparar textos. Por exemplo, com essas licenças de código aberto, podemos baixar o texto, analisar e comparar as métricas de [semelhança](https://spacy.io/api/doc#similarity) entre elas:"
      ],
      "metadata": {
        "id": "mrz1E8snZLJa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "9C4fhTj-Fdtw",
        "outputId": "c59534c2-6aca-4758-e2d1-033dc3387de0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mit asl 0.9258679257488884\n",
            "asl bsd 0.9156873661726042\n",
            "bsd mit 0.9876502364072113\n"
          ]
        }
      ],
      "source": [
        "pairs = [\n",
        "    [\"mit\", \"asl\"],\n",
        "    [\"asl\", \"bsd\"],\n",
        "    [\"bsd\", \"mit\"]\n",
        "]\n",
        "\n",
        "for a, b in pairs:\n",
        "    print(a, b, lic[a].similarity(lic[b]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Isso é interessante, pois as licenças [BSD](https://opensource.org/licenses/BSD-3-Clause) e [MIT](https://opensource.org/licenses/MIT) parecem ser as mais semelhantes documentos.\n",
        "Na verdade, eles estão intimamente relacionados.\n",
        "\n",
        "É certo que houve algum texto extra incluído em cada documento devido à isenção de responsabilidade da OSI no rodapé - mas isso fornece uma aproximação razoável para comparar as licenças."
      ],
      "metadata": {
        "id": "eeng7Bz9ZUr1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compreensão da linguagem natural (NLU)\n",
        "\n",
        "Agora vamos mergulhar em alguns dos recursos do spaCy para NLU.\n",
        "\n",
        "Dado que temos uma análise sintática de um documento, de um ponto de vista puramente gramatical, podemos extrair os [*noun chunks*](https://spacy.io/usage/linguistic-features#noun-chunks), ou seja, cada uma das frases nominais.\n",
        "\n",
        "Para entender melhor, *noun chunks* são “frases nominais básicas”, isto é, frases planas que têm um substantivo como cabeça. Você pode pensar em pedaços de substantivos como um substantivo mais as palavras que descrevem o substantivo.\n",
        "\n",
        "Por exemplo, \"a grama verde pródiga\" ou \"o maior fundo de tecnologia do mundo\". Para obter os pedaços de substantivo em um documento, basta iterar sobre."
      ],
      "metadata": {
        "id": "1a_vP6YwZhuN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ovMY-si9Fdtx",
        "outputId": "d33d24c0-f46b-4e77-f387-0aac4164353b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steve Jobs e Steve Wozniak\n",
            "Apple Computer\n",
            "janeiro\n",
            "Cupertino\n",
            ", Califórnia\n"
          ]
        }
      ],
      "source": [
        "text = \"Steve Jobs e Steve Wozniak fundaram a Apple Computer em 3 de janeiro de 1977, em Cupertino, Califórnia.\"\n",
        "doc = nlp(text)\n",
        "\n",
        "for chunk in doc.noun_chunks:\n",
        "    print(chunk.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Os sintagmas nominais em uma frase geralmente fornecem mais conteúdo informativo, como um simples filtro usado para reduzir um documento longo em uma representação mais \"destilada\".\n",
        "\n",
        "Podemos levar essa abordagem adiante e identificar Entidades [named entities](https://spacy.io/usage/linguistic-features#named-entities) dentro do texto, ou seja, os nomes próprios:"
      ],
      "metadata": {
        "id": "4oQXFjEAaKdq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "emsN2WxMFdtx",
        "outputId": "872671d0-16a4-40d7-b495-fd508c83284c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steve Jobs PER\n",
            "Steve Wozniak PER\n",
            "Apple Computer ORG\n",
            "Cupertino LOC\n",
            "Califórnia LOC\n"
          ]
        }
      ],
      "source": [
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCwGm9XlFdty"
      },
      "source": [
        "Voltamos a usar a biblioteca displaCy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "t_sz7QsdFdty",
        "outputId": "3821b692-34d8-401e-96b0-2c49b58a4dae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Steve Jobs\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              " e \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Steve Wozniak\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              " fundaram a \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Apple Computer\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " em 3 de janeiro de 1977, em \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Cupertino\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              ", \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Califórnia\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              ".</div></span>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "displacy.render(doc, style=\"ent\", jupyter=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se você estiver trabalhando com aplicativos de [gráfico de conhecimento](https://www.akbc.ws/) e outros [dados vinculados](http://linkeddata.org/), seu desafio é construir links entre as entidades nomeadas em um documento e outras informações relacionadas às entidades – que é chamado de [entity linking](http://nlpprogress.com/english/entity_linking.html).\n",
        "\n",
        "Identificar as entidades nomeadas em um documento é o primeiro passo nesse tipo específico de trabalho de IA.\n",
        "\n",
        "Por exemplo, dado o texto acima, pode-se vincular a entidade nomeada `Steve Wozniak` a uma [pesquisa na DBpedia](http://dbpedia.org/page/Steve_Wozniak)."
      ],
      "metadata": {
        "id": "nW3eRUkzant9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Considerações finais**\n",
        "\n",
        "Cinco anos atrás, se você perguntasse sobre código aberto em Python para linguagem natural, uma resposta padrão de muitas pessoas que trabalham em ciência de dados seria [NLTK](https://www.nltk.org/).\n",
        "\n",
        "Esse projeto inclui quase tudo, menos a pia da cozinha, e tem componentes relativamente acadêmicos.\n",
        "\n",
        "Outro projeto popular de linguagem natural é o [CoreNLP](https://stanfordnlp.github.io/CoreNLP/) de Stanford.\n",
        "\n",
        "Também bastante acadêmico, embora poderoso, embora o _CoreNLP_ possa ser um desafio para integrar com outros softwares para uso em produção.\n",
        "\n",
        "Porém, há alguns anos, tudo em linguagem natural começou a mudar. Os dois principais autores de _spaCy_ -- [Matthew Honnibal](https://twitter.com/honnibal) e [Ines Montani](https://twitter.com/_inesmontani) -- lançaram o projeto em 2015 e a adoção da indústria foi rápido.\n",
        "\n",
        "Eles se concentraram em uma abordagem _opinativa_ (faça o que é necessário, faça bem, nem mais, nem menos) que forneceu integração simples e rápida em fluxos de trabalho de ciência de dados em Python, bem como execução mais rápida e melhor precisão do que as alternativas.\n",
        "\n",
        "Com base nessas prioridades, _spaCy_ se torna o oposto de _NLTK_.\n",
        "\n",
        "Desde 2015, o _spaCy_ tem se concentrado consistentemente em ser um projeto de código aberto (ou seja, dependendo de sua comunidade para direções, integrações etc.) e em ser um software de nível comercial (não pesquisa acadêmica).\n",
        "\n",
        "Dito isso, a _spaCy_ foi rápida em incorporar os avanços da SOTA no aprendizado de máquina, tornando-se efetivamente um canal para mover a pesquisa para a indústria.\n",
        "\n",
        "É importante notar que o aprendizado de máquina para linguagem natural teve um grande impulso em meados dos anos 2000, quando o Google começou a ganhar competições internacionais de tradução de idiomas.\n",
        "\n",
        "Outra grande mudança ocorreu durante 2017-2018 quando, após os muitos sucessos do _deep learning_, essas abordagens começaram a superar os modelos anteriores de aprendizado de máquina.\n",
        "\n",
        "Por exemplo, veja o trabalho [ELMo](https://arxiv.org/abs/1802.05365) sobre _language embedding_ por Allen AI, seguido por [BERT](https://ai.googleblog.com/2018/11/open -sourcing-bert-state-of-art-pre.html) do Google e, mais recentemente, [ERNIE](https://medium.com/syncedreview/baidus-ernie-tops-google-s-bert-in-chinese -nlp-tasks-d6a42b49223d) por Baidu -- em outras palavras, os gigantes dos mecanismos de busca do mundo presentearam o resto de nós com um repertório da Vila Sésamo de modelos de linguagem incorporados de código aberto baseados em aprendizado profundo, que agora é _estado do mundo arte_ (SOTA).\n",
        "\n",
        "Falando nisso, para acompanhar SOTA para linguagem natural, fique de olho em [NLP-Progress](http://nlpprogress.com/) e [Papers with Code](https://paperswithcode.com/sota).\n",
        "\n",
        "Os casos de uso da linguagem natural mudaram drasticamente nos últimos anos, depois que as técnicas de aprendizado profundo surgiram.\n",
        "\n",
        "Por volta de 2014, um tutorial de linguagem natural em Python pode ter mostrado _contagem de palavras_ ou _pesquisa de palavras-chave_ ou _detecção de sentimentos_ onde os casos de uso de destino eram relativamente abaixo do esperado.\n",
        "\n",
        "Pós 2020, estamos falando de analisar milhares de documentos para contratos de fornecedores em uma otimização da cadeia de suprimentos industrial... ou centenas de milhões de documentos para segurados de uma seguradora, ou zilhões de documentos sobre divulgações financeiras.\n",
        "\n",
        "O trabalho de linguagem natural mais contemporâneo tende a ser em NLU, muitas vezes para apoiar a construção de _gráficos de conhecimento,_ e cada vez mais em NLG, onde um grande número de documentos semelhantes pode ser resumido em escala humana.\n",
        "\n",
        "O [spaCy Universe](https://spacy.io/universe) é um ótimo lugar para verificar aprofundamentos em casos de uso específicos e ver como esse campo está evoluindo. Algumas seleções deste \"universo\" incluem:\n",
        "\n",
        " - [Blackstone](https://spacy.io/universe/project/blackstone) – analisando textos legais não estruturados\n",
        " - [Kindred](https://spacy.io/universe/project/kindred) – extraindo entidades de textos biomédicos (por exemplo, Pharma)\n",
        " - [mordecai](https://spacy.io/universe/project/mordecai) – analisando informações geográficas\n",
        " - [Prodigy](https://spacy.io/universe/project/prodigy) – anotação humana no loop para rotular conjuntos de dados\n",
        " - [spacy-raspberry](https://spacy.io/universe/project/spacy-raspberry) – Imagem do Raspberry PI para execução de _spaCy_ e aprendizado profundo em dispositivos de borda\n",
        " - [Rasa NLU](https://spacy.io/universe/project/rasa) – Integração Rasa para aplicativos de voz\n",
        "\n",
        "Além disso, alguns itens super novos para mencionar:\n",
        "\n",
        "  - [spacy-pytorch-transformers](https://explosion.ai/blog/spacy-pytorch-transformers) para ajustar (ou seja, usar _transfer learning_ com) os personagens e amigos da Vila Sésamo: BERT, GPT-2, XLNet , etc\n",
        "  - [spaCy IRL 2019](https://irl.spacy.io/2019/) conferência – confira os vídeos das palestras!\n",
        "\n",
        "Há muito mais que pode ser feito com _spaCy_, é claro."
      ],
      "metadata": {
        "id": "YUkL1t0_YsZA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYJXIfJxFdt3"
      },
      "source": [
        "---\n",
        "\n",
        "Notebook utilizado para fins educacionais da **Awari**.\n",
        "\n",
        "**© AWARI. Todos os direitos reservados.**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "CKsHxTf-Sa6c"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}